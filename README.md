# speech_emotion_recognition

https://www.kaggle.com/datasets/ejlok1/toronto-emotional-speech-set-tess use this for dataset.

<br>

### Methodology process

1)Pre-processing: Accepts a voice from the dataset for emotion recognition.<br>
2)Feature extraction: It extracts the feature from the audio file based on how we speak(tone,pitch,etc).<br>
3)Classification: It matches the feature with corresponding emotions from the dataset.<br>
### The two main concepts are:<br>
#### MFCC: (mel - frequency cepstral coefficients)<br>
      - It is used for representation of the spectral property of voice signals.<br>
#### Feature extraction:<br>
     - It is used for changing the speech waveform to a form of parametric representation at a relatively lesser data rate for subsequent processing and analysis.<br>
Since we using the above concepts, the system will be capable of:<br>
-> Improving learning performance.<br>
-> Lowering computational complexity.<br>
-> Building better generalizable models.<br>
-> Decreasing required storage.

<br>

## Loading the Dataset:
Two actresses (ages 26 and 64) spoke 200 target words in the carrier phrase "Say the word" and recorded phrases representing each of seven emotions (anger, disgust, fear, happiness, and joy). did. There are a total of 2800 data points (audio files).The data set is organized so that each of the two actresses and their emotions is in its own folder. In it you will find all the words of the 200 target audio files. The audio file format is WAV format.<br>
## Hardware Requirements
1.Laptop or PC<br>
2.I5 processor System or higher<br>
3.4GB RAM or higher<br>
4.windows 10 version<br>
## Software Requirements
i)  Data and implementation requirements :
     <br>A platform to implement and test the model (Kaggle)
<br>TESS dataset (TORONTO EMOTION SPEECH SET)<br>
ii) Skills required :
<br>Basic knowledge about python.
<br>Basic knowledge about ML algorithms.
<br>Knowledge about model making and testing
